{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "0KQI4beK724N",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ee6f3fc1-476a-4792-d6fc-b30fe6b26ef6"
      },
      "source": [
        "import requests\n",
        "import json\n",
        "import torch\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IqBFb_WjGdFI"
      },
      "source": [
        "**Connecting Google Drive in order to save the model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ressj5OzXrCc"
      },
      "source": [
        "if not os.path.exists('/content/drive/MyDrive/BERT-SQuAD'):\n",
        "  os.mkdir('/content/drive/MyDrive/BERT-SQuAD')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DE9Wlhn0Dmww",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5b71b005-24a6-43f8-d5fb-32a026dc4830"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.35.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.13.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.0)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.11.17)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X3ULhdPV9OBa"
      },
      "source": [
        "# Load the training dataset and take a look at it\n",
        "with open('train.json', 'rb') as f:\n",
        "  squad = json.load(f)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U0y6ra5A_pwX",
        "outputId": "ce7006d4-327a-40dd-8ba6-ee838202939b"
      },
      "source": [
        "# Each 'data' dict has two keys (title and paragraphs)\n",
        "squad['data'][0].keys()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['paragraphs'])"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_WE2gdsy7SMk"
      },
      "source": [
        "### **Get data üìÅ**\n",
        "\n",
        "After we got a taste of the jsons files data format let's extract our data and store them into some data structures."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F5wGx6bJ-BJC"
      },
      "source": [
        "def read_data(path):\n",
        "  # load the json file\n",
        "  with open(path, 'rb') as f:\n",
        "    squad = json.load(f)\n",
        "\n",
        "  contexts = []\n",
        "  questions = []\n",
        "  answers = []\n",
        "\n",
        "  for group in squad['data']:\n",
        "    for passage in group['paragraphs']:\n",
        "      context = passage['context']\n",
        "      for qa in passage['qas']:\n",
        "        question = qa['question']\n",
        "        for answer in qa['answers']:\n",
        "          contexts.append(context)\n",
        "          questions.append(question)\n",
        "          answers.append(answer)\n",
        "\n",
        "  return contexts, questions, answers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UeKCd5W4SEKY"
      },
      "source": [
        "Put the contexts, questions and answers for training and validation into the appropriate lists."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "An5wY1MNEwrt"
      },
      "source": [
        "train_contexts, train_questions, train_answers = read_data('train.json')\n",
        "valid_contexts, valid_questions, valid_answers = read_data('test.json')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J2AHo87fDYHy"
      },
      "source": [
        "As you can see above, the answers are dictionaries whith the answer text and an integer which indicates the start index of the answer in the context. As the SQuAD does not give us the end index of the answer in the context we have to find it ourselves. So, let's get the character position at which the answer ends in the passage. Note that sometimes SQuAD answers are off by one or two characters, so we will also adjust for that."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b9kiFd7LF6xa"
      },
      "source": [
        "def add_end_idx(answers, contexts):\n",
        "  for answer, context in zip(answers, contexts):\n",
        "    gold_text = answer['text']\n",
        "    start_idx = answer['answer_start']\n",
        "    end_idx = start_idx + len(gold_text)\n",
        "\n",
        "    # sometimes squad answers are off by a character or two so we fix this\n",
        "    if context[start_idx:end_idx] == gold_text:\n",
        "      answer['answer_end'] = end_idx\n",
        "    elif context[start_idx-1:end_idx-1] == gold_text:\n",
        "      answer['answer_start'] = start_idx - 1\n",
        "      answer['answer_end'] = end_idx - 1     # When the gold label is off by one character\n",
        "    elif context[start_idx-2:end_idx-2] == gold_text:\n",
        "      answer['answer_start'] = start_idx - 2\n",
        "      answer['answer_end'] = end_idx - 2     # When the gold label is off by two characters\n",
        "\n",
        "add_end_idx(train_answers, train_contexts)\n",
        "add_end_idx(valid_answers, valid_contexts)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hsVHwdOaHWis"
      },
      "source": [
        "### **Tokenization üî¢**\n",
        "\n",
        "As we know we have to tokenize our data in form that is acceptable for the BERT model. We are going to use the `BertTokenizerFast` instead of `BertTokenizer` as the first one is much faster. Since we are going to train our model in batches we need to set `padding=True`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qBLTJaqhHb4J"
      },
      "source": [
        "from transformers import BertTokenizerFast\n",
        "\n",
        "tokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased')\n",
        "\n",
        "train_encodings = tokenizer(train_contexts, train_questions, truncation=True, padding=True)\n",
        "valid_encodings = tokenizer(valid_contexts, valid_questions, truncation=True, padding=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jFEfVQkvTYiI"
      },
      "source": [
        "Let's see what we got after tokenizing our data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dy-e5y5sIKCJ",
        "outputId": "0d7a0f39-ddd3-4257-9093-a06c4896385b"
      },
      "source": [
        "train_encodings.keys()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['input_ids', 'token_type_ids', 'attention_mask'])"
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HK4TXL1CMB0m",
        "outputId": "f0435256-4712-480e-a66f-9bf9bed81540"
      },
      "source": [
        "no_of_encodings = len(train_encodings['input_ids'])\n",
        "print(f'We have {no_of_encodings} context-question pairs')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "We have 51 context-question pairs\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BlmOgSioMcYa",
        "outputId": "8738efde-0bec-45bc-fce1-1afa750a22d9"
      },
      "source": [
        "train_encodings['input_ids'][0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[101,\n",
              " 3653,\n",
              " 25918,\n",
              " 8082,\n",
              " 11616,\n",
              " 1024,\n",
              " 1010,\n",
              " 22822,\n",
              " 17062,\n",
              " 24552,\n",
              " 1012,\n",
              " 1010,\n",
              " 2695,\n",
              " 25918,\n",
              " 8082,\n",
              " 11616,\n",
              " 1024,\n",
              " 1010,\n",
              " 22822,\n",
              " 17062,\n",
              " 24552,\n",
              " 1012,\n",
              " 1010,\n",
              " 7709,\n",
              " 1024,\n",
              " 1010,\n",
              " 5001,\n",
              " 10464,\n",
              " 24895,\n",
              " 14405,\n",
              " 8586,\n",
              " 23518,\n",
              " 14405,\n",
              " 29107,\n",
              " 3367,\n",
              " 7277,\n",
              " 20996,\n",
              " 5602,\n",
              " 1011,\n",
              " 4372,\n",
              " 1011,\n",
              " 1061,\n",
              " 3806,\n",
              " 12412,\n",
              " 11826,\n",
              " 2007,\n",
              " 25212,\n",
              " 2050,\n",
              " 9617,\n",
              " 16033,\n",
              " 15530,\n",
              " 2483,\n",
              " 1012,\n",
              " 1010,\n",
              " 2019,\n",
              " 25344,\n",
              " 1024,\n",
              " 1010,\n",
              " 2236,\n",
              " 2007,\n",
              " 2203,\n",
              " 4140,\n",
              " 22648,\n",
              " 20192,\n",
              " 2140,\n",
              " 20014,\n",
              " 19761,\n",
              " 3508,\n",
              " 1012,\n",
              " 1010,\n",
              " 12407,\n",
              " 2005,\n",
              " 7709,\n",
              " 1024,\n",
              " 1010,\n",
              " 2023,\n",
              " 2003,\n",
              " 1037,\n",
              " 2382,\n",
              " 1011,\n",
              " 2095,\n",
              " 1011,\n",
              " 2214,\n",
              " 2931,\n",
              " 1010,\n",
              " 2040,\n",
              " 2038,\n",
              " 2042,\n",
              " 2058,\n",
              " 11179,\n",
              " 2005,\n",
              " 2116,\n",
              " 2086,\n",
              " 1012,\n",
              " 2016,\n",
              " 2038,\n",
              " 2699,\n",
              " 2116,\n",
              " 2367,\n",
              " 8738,\n",
              " 2015,\n",
              " 1010,\n",
              " 2021,\n",
              " 2003,\n",
              " 7736,\n",
              " 1012,\n",
              " 2016,\n",
              " 2038,\n",
              " 2042,\n",
              " 2000,\n",
              " 2256,\n",
              " 22466,\n",
              " 4017,\n",
              " 7277,\n",
              " 5970,\n",
              " 18014,\n",
              " 1010,\n",
              " 2363,\n",
              " 2070,\n",
              " 2192,\n",
              " 12166,\n",
              " 1010,\n",
              " 1998,\n",
              " 2772,\n",
              " 1996,\n",
              " 9619,\n",
              " 1012,\n",
              " 1996,\n",
              " 10831,\n",
              " 1998,\n",
              " 6666,\n",
              " 1997,\n",
              " 1996,\n",
              " 7709,\n",
              " 2031,\n",
              " 2042,\n",
              " 4541,\n",
              " 2000,\n",
              " 1996,\n",
              " 5776,\n",
              " 1012,\n",
              " 1010,\n",
              " 7709,\n",
              " 1999,\n",
              " 6987,\n",
              " 1024,\n",
              " 1010,\n",
              " 1996,\n",
              " 5776,\n",
              " 2001,\n",
              " 2579,\n",
              " 2000,\n",
              " 1996,\n",
              " 4082,\n",
              " 2282,\n",
              " 1998,\n",
              " 2872,\n",
              " 10514,\n",
              " 19265,\n",
              " 2006,\n",
              " 1996,\n",
              " 4082,\n",
              " 2282,\n",
              " 2795,\n",
              " 1012,\n",
              " 2035,\n",
              " 3778,\n",
              " 2685,\n",
              " 2020,\n",
              " 5362,\n",
              " 20633,\n",
              " 1012,\n",
              " 2016,\n",
              " 2001,\n",
              " 2445,\n",
              " 2236,\n",
              " 2019,\n",
              " 25344,\n",
              " 2007,\n",
              " 2203,\n",
              " 4140,\n",
              " 22648,\n",
              " 20192,\n",
              " 2140,\n",
              " 20014,\n",
              " 19761,\n",
              " 3508,\n",
              " 1012,\n",
              " 8040,\n",
              " 2094,\n",
              " 26412,\n",
              " 2020,\n",
              " 2872,\n",
              " 2006,\n",
              " 2119,\n",
              " 3456,\n",
              " 1012,\n",
              " 17106,\n",
              " 4937,\n",
              " 27065,\n",
              " 2121,\n",
              " 2001,\n",
              " 2872,\n",
              " 2005,\n",
              " 24176,\n",
              " 21933,\n",
              " 8737,\n",
              " 8303,\n",
              " 3258,\n",
              " 1012,\n",
              " 1996,\n",
              " 13878,\n",
              " 2001,\n",
              " 2059,\n",
              " 17463,\n",
              " 5669,\n",
              " 1998,\n",
              " 15098,\n",
              " 1999,\n",
              " 3115,\n",
              " 25403,\n",
              " 11707,\n",
              " 4827,\n",
              " 1012,\n",
              " 7871,\n",
              " 18175,\n",
              " 2001,\n",
              " 2059,\n",
              " 19737,\n",
              " 2083,\n",
              " 8529,\n",
              " 14454,\n",
              " 14239,\n",
              " 1012,\n",
              " 1037,\n",
              " 2235,\n",
              " 4297,\n",
              " 19969,\n",
              " 2001,\n",
              " 2081,\n",
              " 1012,\n",
              " 1037,\n",
              " 2310,\n",
              " 8303,\n",
              " 12201,\n",
              " 2001,\n",
              " 3107,\n",
              " 2046,\n",
              " 1996,\n",
              " 13878,\n",
              " 1012,\n",
              " 2522,\n",
              " 2475,\n",
              " 16021,\n",
              " 16093,\n",
              " 10258,\n",
              " 3370,\n",
              " 2001,\n",
              " 2589,\n",
              " 2000,\n",
              " 1037,\n",
              " 4555,\n",
              " 3778,\n",
              " 1997,\n",
              " 2321,\n",
              " 3461,\n",
              " 25619,\n",
              " 1012,\n",
              " 1037,\n",
              " 2260,\n",
              " 1011,\n",
              " 3461,\n",
              " 18601,\n",
              " 13473,\n",
              " 2361,\n",
              " 3417,\n",
              " 2001,\n",
              " 2872,\n",
              " 2083,\n",
              " 1996,\n",
              " 8529,\n",
              " 14454,\n",
              " 14239,\n",
              " 1012,\n",
              " 1045,\n",
              " 2059,\n",
              " 2872,\n",
              " 1037,\n",
              " 1019,\n",
              " 1011,\n",
              " 3461,\n",
              " 3417,\n",
              " 2074,\n",
              " 15099,\n",
              " 2000,\n",
              " 1996,\n",
              " 3054,\n",
              " 8528,\n",
              " 9386,\n",
              " 2854,\n",
              " 2240,\n",
              " 1998,\n",
              " 2074,\n",
              " 4942,\n",
              " 13186,\n",
              " 9080,\n",
              " 2006,\n",
              " 1996,\n",
              " 2157,\n",
              " 2217,\n",
              " 1012,\n",
              " 1045,\n",
              " 2872,\n",
              " 2178,\n",
              " 1019,\n",
              " 1011,\n",
              " 3461,\n",
              " 3417,\n",
              " 1999,\n",
              " 1996,\n",
              " 3054,\n",
              " 20464,\n",
              " 18891,\n",
              " 15431,\n",
              " 2240,\n",
              " 2074,\n",
              " 4942,\n",
              " 13186,\n",
              " 9080,\n",
              " 2006,\n",
              " 1996,\n",
              " 2157,\n",
              " 2217,\n",
              " 1010,\n",
              " 1037,\n",
              " 2261,\n",
              " 18119,\n",
              " 2917,\n",
              " 1998,\n",
              " 23828,\n",
              " 2000,\n",
              " 2008,\n",
              " 1010,\n",
              " 1045,\n",
              " 2872,\n",
              " 1037,\n",
              " 2260,\n",
              " 1011,\n",
              " 3461,\n",
              " 18601,\n",
              " 13473,\n",
              " 2361,\n",
              " 3417,\n",
              " 1012,\n",
              " 2006,\n",
              " 1996,\n",
              " 2187,\n",
              " 2217,\n",
              " 1010,\n",
              " 2074,\n",
              " 15099,\n",
              " 2000,\n",
              " 1996,\n",
              " 3054,\n",
              " 8528,\n",
              " 9386,\n",
              " 2854,\n",
              " 2240,\n",
              " 1998,\n",
              " 2074,\n",
              " 4942,\n",
              " 13186,\n",
              " 9080,\n",
              " 1010,\n",
              " 1045,\n",
              " 2872,\n",
              " 1037,\n",
              " 1019,\n",
              " 1011,\n",
              " 3461,\n",
              " 3417,\n",
              " 1012,\n",
              " 1037,\n",
              " 2261,\n",
              " 18119,\n",
              " 2917,\n",
              " 1998,\n",
              " 23828,\n",
              " 2000,\n",
              " 2008,\n",
              " 1010,\n",
              " 1045,\n",
              " 2872,\n",
              " 1037,\n",
              " 2321,\n",
              " 1011,\n",
              " 3461,\n",
              " 3417,\n",
              " 1012,\n",
              " 1045,\n",
              " 2211,\n",
              " 2011,\n",
              " 8783,\n",
              " 2039,\n",
              " 1996,\n",
              " 18168,\n",
              " 4765,\n",
              " 2819,\n",
              " 1998,\n",
              " 12151,\n",
              " 1996,\n",
              " 18323,\n",
              " 16844,\n",
              " 1998,\n",
              " 8783,\n",
              " 2008,\n",
              " 2039,\n",
              " 1998,\n",
              " 8558,\n",
              " 12151,\n",
              " 2026,\n",
              " 25641,\n",
              " 1997,\n",
              " 29461,\n",
              " 8838,\n",
              " 1012,\n",
              " 1045,\n",
              " 2743,\n",
              " 1996,\n",
              " 2235,\n",
              " 6812,\n",
              " 2884,\n",
              " 2091,\n",
              " 3155,\n",
              " 2871,\n",
              " 4642,\n",
              " 1998,\n",
              " 4055,\n",
              " 1996,\n",
              " 2235,\n",
              " 6812,\n",
              " 2884,\n",
              " 2007,\n",
              " 1037,\n",
              " 2317,\n",
              " 7170,\n",
              " 27699,\n",
              " 18785,\n",
              " 2099,\n",
              " 1012,\n",
              " 1045,\n",
              " 2059,\n",
              " 4055,\n",
              " 1996,\n",
              " 2033,\n",
              " 5054,\n",
              " 20902,\n",
              " 2035,\n",
              " 1996,\n",
              " 2126,\n",
              " 2091,\n",
              " 2000,\n",
              " 1996,\n",
              " 2918,\n",
              " 1997,\n",
              " 1996,\n",
              " 2033,\n",
              " 5054,\n",
              " 20902,\n",
              " 2007,\n",
              " 1037,\n",
              " 8018,\n",
              " 28632,\n",
              " 5080,\n",
              " 1012,\n",
              " 1045,\n",
              " 2059,\n",
              " 2743,\n",
              " 1996,\n",
              " 29333,\n",
              " 6812,\n",
              " 2884,\n",
              " 2091,\n",
              " 1010,\n",
              " 3155,\n",
              " 2531,\n",
              " 4642,\n",
              " 1010,\n",
              " 1998,\n",
              " 2012,\n",
              " 2531,\n",
              " 4642,\n",
              " 1010,\n",
              " 1045,\n",
              " 2081,\n",
              " 1037,\n",
              " 4920,\n",
              " 2012,\n",
              " 1996,\n",
              " 3424,\n",
              " 7834,\n",
              " 29110,\n",
              " 2594,\n",
              " 4664,\n",
              " 102,\n",
              " 2129,\n",
              " 2214,\n",
              " 2003,\n",
              " 1996,\n",
              " 5776,\n",
              " 1029,\n",
              " 102]"
            ]
          },
          "metadata": {},
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SJZRb9FyKmh2"
      },
      "source": [
        "Let's decode the first pair of context-question encoded pair and look into it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        },
        "id": "D8nEGmjZMIaW",
        "outputId": "d937d7e4-c1e5-4c07-e306-c362c1bce564"
      },
      "source": [
        "tokenizer.decode(train_encodings['input_ids'][0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'[CLS] preoperative diagnosis :, morbid obesity., postoperative diagnosis :, morbid obesity., procedure :, laparoscopic antecolic antegastric roux - en - y gastric bypass with eea anastomosis., anesthesia :, general with endotracheal intubation., indication for procedure :, this is a 30 - year - old female, who has been overweight for many years. she has tried many different diets, but is unsuccessful. she has been to our bariatric surgery seminar, received some handouts, and signed the consent. the risks and benefits of the procedure have been explained to the patient., procedure in detail :, the patient was taken to the operating room and placed supine on the operating room table. all pressure points were carefully padded. she was given general anesthesia with endotracheal intubation. scd stockings were placed on both legs. foley catheter was placed for bladder decompression. the abdomen was then prepped and draped in standard sterile surgical fashion. marcaine was then injected through umbilicus. a small incision was made. a veress needle was introduced into the abdomen. co2 insufflation was done to a maximum pressure of 15 mmhg. a 12 - mm versastep port was placed through the umbilicus. i then placed a 5 - mm port just anterior to the midaxillary line and just subcostal on the right side. i placed another 5 - mm port in the midclavicular line just subcostal on the right side, a few centimeters below and medial to that, i placed a 12 - mm versastep port. on the left side, just anterior to the midaxillary line and just subcostal, i placed a 5 - mm port. a few centimeters below and medial to that, i placed a 15 - mm port. i began by lifting up the omentum and identifying the transverse colon and lifting that up and thereby identifying my ligament of treitz. i ran the small bowel down approximately 40 cm and divided the small bowel with a white load gia stapler. i then divided the mesentery all the way down to the base of the mesentery with a ligasure device. i then ran the distal bowel down, approximately 100 cm, and at 100 cm, i made a hole at the antimesenteric portion [SEP] how old is the patient? [SEP]'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G2Fgedo-Tk8n"
      },
      "source": [
        "We can see that each word is assigned a number.\n",
        "\n",
        "For example,\n",
        "\n",
        "beyonce $\\rightarrow$ 20773  \n",
        "[CLS] $\\rightarrow$ 101  \n",
        "[SEP] $\\rightarrow$ 102   \n",
        "[PAD] $\\rightarrow$ 0  \n",
        "\n",
        "We see that the above form matches the one in the image we saw in the Data preprocessing section before."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gADJPJH_VBcQ"
      },
      "source": [
        "Next we need to convert our character start/end positions to token start/end positions. Why is that? Because our words converted into tokens, so the answer start/end needs to show the index of start/end token which contains the answer and not the specific characters in the context."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r7uXDM0mMfOo"
      },
      "source": [
        "def add_token_positions(encodings, answers):\n",
        "  start_positions = []\n",
        "  end_positions = []\n",
        "  for i in range(len(answers)):\n",
        "    start_positions.append(encodings.char_to_token(i, answers[i]['answer_start']))\n",
        "    end_positions.append(encodings.char_to_token(i, answers[i]['answer_end'] - 1))\n",
        "\n",
        "    # if start position is None, the answer passage has been truncated\n",
        "    if start_positions[-1] is None:\n",
        "      start_positions[-1] = tokenizer.model_max_length\n",
        "    if end_positions[-1] is None:\n",
        "      end_positions[-1] = tokenizer.model_max_length\n",
        "\n",
        "  encodings.update({'start_positions': start_positions, 'end_positions': end_positions})\n",
        "\n",
        "add_token_positions(train_encodings, train_answers)\n",
        "add_token_positions(valid_encodings, valid_answers)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cU-mZO2RMwVl",
        "outputId": "353c3be8-992d-4386-f497-729a00cb3c08"
      },
      "source": [
        "train_encodings['start_positions'][:10]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[78, 512, 88, 42, 7, 512, 312, 86, 512, 46]"
            ]
          },
          "metadata": {},
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rRnqbmjD3Lip"
      },
      "source": [
        "### **Dataset definition üóÑÔ∏è**\n",
        "\n",
        "We have to define our dataset using the PyTorch Dataset class from `torch.utils` in order create our dataloaders after that."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JC5t8iOyORg-"
      },
      "source": [
        "class SQuAD_Dataset(torch.utils.data.Dataset):\n",
        "  def __init__(self, encodings):\n",
        "    self.encodings = encodings\n",
        "  def __getitem__(self, idx):\n",
        "    return {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "  def __len__(self):\n",
        "    return len(self.encodings.input_ids)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RfpQgBOCPLwh"
      },
      "source": [
        "train_dataset = SQuAD_Dataset(train_encodings)\n",
        "valid_dataset = SQuAD_Dataset(valid_encodings)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8APUSaCswlID"
      },
      "source": [
        "### **Dataloaders üîÅ**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ROBQQLmNwGbb"
      },
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# Define the dataloaders\n",
        "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
        "valid_loader = DataLoader(valid_dataset, batch_size=16)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TkkgktrwPYhy"
      },
      "source": [
        "## **Fine-Tuning ‚öôÔ∏è**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K8lPIP0zl5uD",
        "outputId": "154a2b0c-01e4-4d7d-cf61-5ed416b02626"
      },
      "source": [
        "from transformers import BertForQuestionAnswering\n",
        "\n",
        "model = BertForQuestionAnswering.from_pretrained(\"bert-base-uncased\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForQuestionAnswering were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['qa_outputs.weight', 'qa_outputs.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JBKY-irY25_F"
      },
      "source": [
        "### **Training üèãÔ∏è‚Äç‚ôÇÔ∏è**\n",
        "\n",
        "Œúy choices for some parameters:\n",
        "\n",
        "* Use of `AdamW` which is a stochastic optimization method that modifies the typical implementation of weight decay in Adam, by decoupling weight decay from the gradient update. This helps to avoid overfitting which is necessary in this case were the model is very complex.\n",
        "\n",
        "* Set the `lr=5e-5` as I read that this is the best value for the learning rate for this task."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kh_2--xXwW6o",
        "outputId": "92e5c0fa-ea08-4760-fbb7-02f3201d8eae"
      },
      "source": [
        "# Check on the available device - use GPU\n",
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "print(f'Working on {device}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Working on cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jOXHj73UEh7f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c99a394c-7867-471b-fcae-50fa37a14397"
      },
      "source": [
        "from transformers import AdamW\n",
        "\n",
        "N_EPOCHS = 30\n",
        "optim = AdamW(model.parameters(), lr=5e-5)\n",
        "\n",
        "model.to(device)\n",
        "model.train()\n",
        "\n",
        "for epoch in range(N_EPOCHS):\n",
        "  loop = tqdm(train_loader, leave=True)\n",
        "  for batch in loop:\n",
        "    optim.zero_grad()\n",
        "    input_ids = batch['input_ids'].to(device)\n",
        "    attention_mask = batch['attention_mask'].to(device)\n",
        "    start_positions = batch['start_positions'].to(device)\n",
        "    end_positions = batch['end_positions'].to(device)\n",
        "    outputs = model(input_ids, attention_mask=attention_mask, start_positions=start_positions, end_positions=end_positions)\n",
        "    loss = outputs[0]\n",
        "    loss.backward()\n",
        "    optim.step()\n",
        "\n",
        "    loop.set_description(f'Epoch {epoch+1}')\n",
        "    loop.set_postfix(loss=loss.item())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n",
            "Epoch 1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:05<00:00,  1.25s/it, loss=1.18]\n",
            "Epoch 2: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:05<00:00,  1.28s/it, loss=0.543]\n",
            "Epoch 3: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:05<00:00,  1.29s/it, loss=0.617]\n",
            "Epoch 4: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:05<00:00,  1.31s/it, loss=1.06]\n",
            "Epoch 5: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:05<00:00,  1.33s/it, loss=0.28]\n",
            "Epoch 6: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:05<00:00,  1.34s/it, loss=0.0868]\n",
            "Epoch 7: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:05<00:00,  1.33s/it, loss=0.412]\n",
            "Epoch 8: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:05<00:00,  1.31s/it, loss=0.0186]\n",
            "Epoch 9: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:05<00:00,  1.29s/it, loss=0.061]\n",
            "Epoch 10: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:05<00:00,  1.28s/it, loss=0.751]\n",
            "Epoch 11: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:05<00:00,  1.27s/it, loss=0.0822]\n",
            "Epoch 12: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:05<00:00,  1.25s/it, loss=0.446]\n",
            "Epoch 13: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:04<00:00,  1.24s/it, loss=0.0177]\n",
            "Epoch 14: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:04<00:00,  1.24s/it, loss=0.143]\n",
            "Epoch 15: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:04<00:00,  1.23s/it, loss=0.339]\n",
            "Epoch 16: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:04<00:00,  1.23s/it, loss=0.752]\n",
            "Epoch 17: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:04<00:00,  1.23s/it, loss=0.0373]\n",
            "Epoch 18: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:04<00:00,  1.23s/it, loss=0.368]\n",
            "Epoch 19: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:04<00:00,  1.24s/it, loss=0.106]\n",
            "Epoch 20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:04<00:00,  1.23s/it, loss=0.0126]\n",
            "Epoch 21: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:04<00:00,  1.24s/it, loss=0.0111]\n",
            "Epoch 22: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:05<00:00,  1.25s/it, loss=0.0814]\n",
            "Epoch 23: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:05<00:00,  1.25s/it, loss=0.228]\n",
            "Epoch 24: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:05<00:00,  1.26s/it, loss=0.0327]\n",
            "Epoch 25: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:05<00:00,  1.27s/it, loss=0.0231]\n",
            "Epoch 26: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:05<00:00,  1.27s/it, loss=0.00392]\n",
            "Epoch 27: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:05<00:00,  1.27s/it, loss=0.0149]\n",
            "Epoch 28: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:05<00:00,  1.27s/it, loss=0.0266]\n",
            "Epoch 29: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:05<00:00,  1.26s/it, loss=0.0204]\n",
            "Epoch 30: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:05<00:00,  1.27s/it, loss=0.00427]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DFY9n5hSFjfT"
      },
      "source": [
        "**Save the model in my drive in order not to run it each time**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p4NXG5UGWWQ9"
      },
      "source": [
        "#model_path = '/content/drive/MyDrive/BERT-SQuAD'\n",
        "#model.save_pretrained(model_path)\n",
        "#tokenizer.save_pretrained(model_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CuFwUaF8BR3H"
      },
      "source": [
        "**Respectively, load the saved model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aslUE82N73mu"
      },
      "source": [
        "#from transformers import BertForQuestionAnswering, BertTokenizerFast\n",
        "\n",
        "#model_path = '/content/drive/MyDrive/BERT-SQuAD'\n",
        "#model = BertForQuestionAnswering.from_pretrained(model_path)\n",
        "#tokenizer = BertTokenizerFast.from_pretrained(model_path)\n",
        "\n",
        "#device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "#print(f'Working on {device}')\n",
        "\n",
        "#model = model.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vIuUtJhBFo5l"
      },
      "source": [
        "### **Testing ‚úÖ**\n",
        "\n",
        "We are evaluating the model on the validation set by checking the model's predictions for the answer's start and end indexes and comparing with the true ones."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JZd-NV1WxOZg",
        "outputId": "4e319de2-f15e-4497-e4b7-9fb3be59913f"
      },
      "source": [
        "from sklearn.metrics import f1_score\n",
        "\n",
        "model.eval()\n",
        "\n",
        "acc = []\n",
        "f1_scores = []\n",
        "exact_matches = []\n",
        "\n",
        "for batch in tqdm(valid_loader):\n",
        "    with torch.no_grad():\n",
        "        input_ids = batch['input_ids'].to(device)\n",
        "        attention_mask = batch['attention_mask'].to(device)\n",
        "        start_true = batch['start_positions'].to(device)\n",
        "        end_true = batch['end_positions'].to(device)\n",
        "\n",
        "        outputs = model(input_ids, attention_mask=attention_mask)\n",
        "\n",
        "        start_pred = torch.argmax(outputs['start_logits'], dim=1)\n",
        "        end_pred = torch.argmax(outputs['end_logits'], dim=1)\n",
        "\n",
        "        # Accuracy calculation\n",
        "        start_acc = (start_pred == start_true).sum().item() / len(start_pred)\n",
        "        end_acc = (end_pred == end_true).sum().item() / len(end_pred)\n",
        "        acc.append(start_acc)\n",
        "        acc.append(end_acc)\n",
        "\n",
        "        # F1 score calculation\n",
        "        for i in range(len(start_true)):\n",
        "            true_span = set(range(start_true[i].item(), end_true[i].item() + 1))\n",
        "            pred_span = set(range(start_pred[i].item(), end_pred[i].item() + 1))\n",
        "\n",
        "            # F1 score\n",
        "            intersection = len(true_span.intersection(pred_span))\n",
        "            precision = intersection / len(pred_span) if len(pred_span) > 0 else 0\n",
        "            recall = intersection / len(true_span) if len(true_span) > 0 else 0\n",
        "            f1 = 2 * (precision * recall) / (precision + recall) if precision + recall > 0 else 0\n",
        "            f1_scores.append(f1)\n",
        "\n",
        "            # Exact match\n",
        "            exact_match = 1 if true_span == pred_span else 0\n",
        "            exact_matches.append(exact_match)\n",
        "\n",
        "acc = sum(acc) / len(acc)\n",
        "f1_avg = sum(f1_scores) / len(f1_scores)\n",
        "exact_match_percentage = sum(exact_matches) / len(exact_matches)\n",
        "\n",
        "print(f\"Average Accuracy: {acc}\")\n",
        "print(f\"Average F1 Score: {f1_avg}\")\n",
        "print(f\"Exact Match Percentage: {exact_match_percentage}\")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.15it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Accuracy: 0.625\n",
            "Average F1 Score: 0.5150013762730525\n",
            "Exact Match Percentage: 0.5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    }
  ]
}